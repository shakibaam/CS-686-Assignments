# ðŸ“˜ CS686: Introduction to AI - Assignments

Welcome to the assignment repository for the **CS686 - Introduction to AI** course! This repository contains all the assignments and resources you'll need for the course. Dive in and explore the fascinating world of Artificial Intelligence!

## ðŸ“‚ Contents

- [Assignment 1](https://github.com/shakibaam/CS-686-codes-Intro-to-AI-/tree/main/A1%20LCFS)
- [Assignment 2](https://github.com/shakibaam/CS-686-Assignments/tree/main/Decision%20Tree)
- [Assignment 3](https://github.com/shakibaam/CS-686-Assignments/tree/main/A3)
- [Assignment 4](https://github.com/shakibaam/CS-686-Assignments/tree/main/A4-RL)


## ðŸ“Œ Assignment Overview

Below, you'll find a brief overview of each assignment in the course.

### Assignment 1

- **Description:** Implementing Lowest Cost First Search algorithm with limited frontier size

### Assignment 2

- **Description:** Implementing a decision tree learning algorithm for classifying documents based on word features. Each decision node corresponds to
a word feature, and the leaf nodes correspond to a prediction of what subreddit the article
belongs in.



### Assignment 3

- **Part1:** Implementing  a Naive Bayes classifier for the same data of Assignment 2. The task is to learn a Bayesian network where the root node is the label/category variable with one child variable per word feature.
  
-  **Part2:**  implementing a feedforward neural network from scratch

### Assignment 4
1. Expectation Maximization (EM) on Bayesian Networks
- Construct a **Bayesian Network (BN)** for diagnosing Dunetts Syndrome using prior probabilities.
- Use **Expectation Maximization (EM)** on a dataset of 2000 patients to estimate Conditional Probability Tables (CPTs).
- Run **EM across different noise levels (Î´)** and analyze sensitivity to initial parameter estimates.
- Validate the learned model using 100 test instances and measure accuracy.
- Generate a **graph of prediction accuracy** before and after EM across different Î´ values.

2. Reinforcement Learning with Emergent Communication
- Implement **two Q-learning agents** (Sender & Receiver) in a **5Ã—5 grid-world** where the sender communicates the location of a hidden prize.
- Train the agents to **develop a communication protocol** using Q-learning.
- Perform experiments on different environments (**Four Rooms, Maze, and Empty Grid**) and varying **message sizes (N) and exploration rates (Ïµ)**.
- Measure **average discounted rewards** across multiple episodes and plot results.
- Show examples of **learned policies** for different environments.





